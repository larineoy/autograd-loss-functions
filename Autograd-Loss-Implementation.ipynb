{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operations import Add, Subtract, Multiply, Divide, Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Number(object):\n",
    "    def __repr__(self):\n",
    "        return \"Number({})\".format(self.data)\n",
    "\n",
    "    def __init__(self, obj, *, creator=None):\n",
    "        assert isinstance(obj, (Number, int, float, np.generic))\n",
    "        self.data = obj.data if isinstance(obj, Number) else obj\n",
    "        self._creator = creator\n",
    "        self.grad = None\n",
    "\n",
    "    @property\n",
    "    def creator(self):\n",
    "        return self._creator\n",
    "    \n",
    "    @staticmethod\n",
    "    def _op(Op, a, b):\n",
    "        if not isinstance(a, Number):\n",
    "            a = Number(a)\n",
    "        if not isinstance(b, Number):\n",
    "            b = Number(b)\n",
    "            \n",
    "        result = f(a, b)\n",
    "        return Number(result, creator=f)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self._op(Add, self, other)\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self._op(Add, other, self)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        return self._op(Multiply, self, other)\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self._op(Multiply, other, self)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return self._op(Divide, self, other)\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return self._op(Divide, other, self)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return self._op(Subtract, self, other)\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self._op(Subtract, other, self)\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        return self._op(Power, self, other)\n",
    "\n",
    "    def __rpow__(self, other):\n",
    "        return self._op(Power, other, self)\n",
    "\n",
    "    def __neg__(self):\n",
    "        return -1*self\n",
    "    \n",
    "    def __eq__(self, value):\n",
    "        if isinstance(value, Number):\n",
    "            value = value.data\n",
    "        return self.data == value\n",
    "\n",
    "    def backprop(self, grad=1):\n",
    "        if self.grad is None:\n",
    "            self.grad = grad\n",
    "        else:\n",
    "            self.grad += grad\n",
    "        \n",
    "        if self._creator is not None:\n",
    "            self._creator.backprop(grad = grad)\n",
    "    \n",
    "    def null_gradients(self):\n",
    "        self.grad = None\n",
    "        if self._creator is not None:\n",
    "            self._creator.null_gradients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9]\n",
    "}\n",
    "\n",
    "# The following line will create a list of data points. It does this by:\n",
    "# 1. creating a list containing each of the lists in `data`\n",
    "# 2. unpacking the lists from (1) and passing them into `zip`\n",
    "# 3. using `zip` to wrap the elements from each list together in tuples\n",
    "# 4. using the elements output from `zip` to create a list\n",
    "data_set = list(zip(*[data[key] for key in data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85.1, 8.5, 5.1, 4.7),\n",
       " (106.3, 12.9, 5.8, 8.8),\n",
       " (50.2, 5.2, 2.1, 15.1),\n",
       " (130.6, 10.7, 8.4, 12.2),\n",
       " (54.8, 3.1, 2.9, 10.6),\n",
       " (30.3, 3.5, 1.2, 3.5),\n",
       " (79.4, 9.2, 3.7, 9.7),\n",
       " (91.0, 9.0, 7.6, 5.9),\n",
       " (135.4, 15.1, 7.7, 20.8),\n",
       " (89.3, 10.2, 4.5, 7.9)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set # display the dataset to see it is a list of data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(truth, model):\n",
    "    l = truth[0] - model[0] - sum(truth[i]*model[i] for i in range(1, len(model)))\n",
    "    return l**2 if l.data > 0 else (-1*l)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_params):\n",
    "    return tuple(Number(np.random.rand()) for _ in range(num_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_set, loss_fn, lr=0.001):\n",
    "    # compute the mean error over the dataset\n",
    "    mean_loss = sum(loss_fn(sample, model) for sample in data_set) / len(data_set)\n",
    "    \n",
    "    # compute gradients for our parameters\n",
    "    mean_loss.null_gradients()\n",
    "    mean_loss.backprop()\n",
    "    \n",
    "    # update the model parameters using gradient descent\n",
    "    for param in model:\n",
    "        # computes: param_new = param_old - step-size * d(L)/d(param) \n",
    "        param.data -= lr*param.grad  \n",
    "        \n",
    "    # return the loss for visualization\n",
    "    return mean_loss.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(train_epoch(model, data_set, l2_loss))\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_set, loss_fn, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m(model, data_set, loss_fn, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# compute the mean error over the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     mean_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_fn(sample, model) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data_set) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_set)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# compute gradients for our parameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     mean_loss\u001b[38;5;241m.\u001b[39mnull_gradients()\n",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m(model, data_set, loss_fn, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# compute the mean error over the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     mean_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_fn(sample, model) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data_set) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_set)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# compute gradients for our parameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     mean_loss\u001b[38;5;241m.\u001b[39mnull_gradients()\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36ml2_loss\u001b[0;34m(truth, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21ml2_loss\u001b[39m(truth, model):\n\u001b[0;32m----> 2\u001b[0m     l \u001b[38;5;241m=\u001b[39m truth[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m model[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(truth[i]\u001b[38;5;241m*\u001b[39mmodel[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(model)))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m l\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m l\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39ml)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 47\u001b[0m, in \u001b[0;36mNumber.__rsub__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(Subtract, other, \u001b[38;5;28mself\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mNumber._op\u001b[0;34m(Op, a, b)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, Number):\n\u001b[1;32m     20\u001b[0m     b \u001b[38;5;241m=\u001b[39m Number(b)\n\u001b[0;32m---> 22\u001b[0m result \u001b[38;5;241m=\u001b[39m f(a, b)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Number(result, creator\u001b[38;5;241m=\u001b[39mf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "model = create_model(4)\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    losses.append(train_epoch(model, data_set, l2_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Training Step');\n",
    "ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(truth, model):\n",
    "    l = truth[0] - model[0] - sum(truth[i]*model[i] for i in range(1, len(model)))\n",
    "    return l if l.data > 0 else (-1*l)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(4)\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    the_loss = train_epoch(model, data_set, l1_loss)\n",
    "    losses.append(the_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Training Step');\n",
    "ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Box Office Sales': [85.1, 106.3, 50.2, 130.6, 54.8, 30.3, 79.4, 91.0, 135.4, 89.3],\n",
    "    'Production Costs': [8.5, 12.9, 5.2, 10.7, 3.1, 3.5, 9.2, 9.0, 15.1, 10.2],\n",
    "    'Promotion Costs': [5.1, 5.8, 2.1, 8.4, 2.9, 1.2, 3.7, 7.6, 7.7, 4.5],\n",
    "    'Book Sales': [4.7, 8.8, 15.1, 12.2, 10.6, 3.5, 9.7, 5.9, 20.8, 7.9],\n",
    "    'Random1': [np.random.rand() for _ in range(10)],\n",
    "    'Random2': [np.random.rand() for _ in range(10)],\n",
    "    'Random3': [np.random.rand() for _ in range(10)]\n",
    "}\n",
    "\n",
    "data_set = list(zip(*[data[key] for key in data]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(7)\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    the_loss = train_epoch(model, data_set, l2_loss)\n",
    "    losses.append(the_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Training Step');\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to visualize what weighting your model learned\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.barh(np.arange(6), [model[i].data for i in range(1, len(model))])\n",
    "ax.set_yticks([0, 1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(['Production Costs', 'Promotion Costs', 'Book Sales', 'Random1',\n",
    "                    'Random2', 'Random3'])\n",
    "ax.set_xlabel('Learned Weights');\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
